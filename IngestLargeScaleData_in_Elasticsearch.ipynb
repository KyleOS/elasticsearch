{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://miro.medium.com/max/1200/1*YN5uqQ79Cr6ArJokrhKvPg.png\"  alt=\"Girl in a jacket\" width=\"700\" height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family:courier;\",align=\"center\">Ingest Large Scale Data in Elasticsearch from Database Technologies</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in this blog we are going to get hands on experience by Ingesting large scale of data into Elasticsearch by extracting data using one of any most popoular database technologies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps to Complete this Capstone Project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Important Python Libraries \n",
    "2. Extract Data from Microsoft SQL Server Database\n",
    "3. Apply Essential Transformations on Pandas Data-frames\n",
    "4. Convert Data into Appropriate Format for Elasticsearch\n",
    "5. Execute Ingestion for Bulk Container into Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import bson\n",
    "import pprint\n",
    "import json\n",
    "import requests\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pandas: pandas is a library of Python that provides high-level data structures and a big variety of functions for data analysis and transformation. Pandas features are Iteration, Sorting, Aggregations, Concatenations and re-indexing the data-frame entries.\n",
    "2. Numpy: numpy is known as one of the most popular library of Python. Numpy internally performing multiple operations with many other libraries. Array interface is very best and the most important feature of Numpy\n",
    "3. PPrint: pprint is a special library which is very helpful for developer when they work with large nested documents of json.\n",
    "4. Json : json is use to work shape data in json formate correctly. \n",
    "5. Requests : requests python library can confirm about the server running apps status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up ElasticSearch with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May be you already have setup ElasticSearch and have a Python environment ready but if not have setup yet then let go to setup ElasticSearch Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the elasticsearch package with pip command:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features of Elasticsearch Python Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Translating basic Python data types to and from json (datetimes are not decoded for performance reasons)\n",
    "configurable automatic discovery of cluster nodes\n",
    "2. Persistent connections\n",
    "3. Load balancing (with pluggable selection strategy) across all available nodes\n",
    "4. Failed connection penalization (time based - failed connections won’t be retried until a timeout is reached)\n",
    "5. Support for ssl and http authentication\n",
    "7. Pluggable architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Elasticsearch and helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Technologies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://datotainfo.com/img/Technology%20Images/database-technologies.png\"  alt=\"Girl in a jacket\" width=\"600\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can get data from any database technology and can ingest it into Elasticsearch, so here we are goint to use MS Sql Serevr database technology to extrach data into pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up MSSQL with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple database interface for Python that builds on top of FreeTDS to provide a Python DB-API (PEP-249) interface to Microsoft SQL Server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Installing pymssql package with pip command:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install pymssql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features of pymssql  Python Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Unicode Friendly\n",
    "2. Python 3 Friendly\n",
    "3. Works on most popular Operating Systems\n",
    "4. Written in Cython for performance\n",
    "5. Includes a supported and documented low-level module (_mssql) that you can use instead of the DB-API\n",
    "6. Supports stored procedures with both return values and output parameters\n",
    "7. A comprehensive test suite\n",
    "8. Compatible with cooperative multi-tasking systems (gevent, etc.)\n",
    "9. Can be used to connect to Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing pymssql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql as sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish a Connection with Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data ingestion into elasticsearch and retrieving data from elasticsearch, we need to first establish a connection with elasticsearch server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Elasticsearch_URL = \"https://elastic:----------\" # Enter you Elasticsearch Url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Python’s request library to confirm the server is running Elasticsearch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res = requests.get(Elasticsearch_URL)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "es = Elasticsearch([Elasticsearch_URL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data from Microsoft SQL Server Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establish a Connection with SQL Server"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SERVER = '--.--.---.--' \n",
    "USER = 'SQL_UserName'\n",
    "PASSWORD = 'SQL_Password'\n",
    "DATABASE = 'SQl_Database_Name'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def GetDatabaseConnection():\n",
    "    return sql.connect(SERVER, USER, PASSWORD, DATABASE)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "db_conn = GetDatabaseConnection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data from MS Sql Server by Sql Queries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('....Loading Households Information....')\n",
    "Household_query = \"\"\"\n",
    "Select * from dbo.Household\n",
    "\"\"\"\n",
    "household_df = pd.read_sql(Household_query, db_conn)\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('....Loading Persons Information....')\n",
    "person_query = \"\"\"\n",
    "Select * from dbo.Person with (nolock)\n",
    "\"\"\"\n",
    "person_df = pd.read_sql(person_query, db_conn).fillna('')\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('....Loading Phones Data....')\n",
    "phone_query = \"\"\"\n",
    "Select * from PersonPhone with (nolock)\n",
    "\"\"\"\n",
    "phones_df = pd.read_sql(phone_query, db_conn).fillna('')\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "household_df.to_pickle('HouseholdData.pkl')\n",
    "person_df.to_pickle('PersonData.pkl')\n",
    "phones_df.to_pickle('PhonesData.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are saving the sql extracted data into pkl files for you because we in this notebook we have remove database credentials\n",
    "for securit pourpose but you can get same results after reading pkl files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Read Data from Pkl Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_df =  pd.read_pickle('HouseholdData.pkl')\n",
    "person_df =  pd.read_pickle('PersonData.pkl')\n",
    "phones_df =  pd.read_pickle('PhonesData.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Essential Transformations on Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataframes Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3302070 entries, 0 to 3302069\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Dtype         \n",
      "---  ------                -----         \n",
      " 0   AccountId             int64         \n",
      " 1   HouseholdDateCreated  datetime64[ns]\n",
      " 2   AgeRange              object        \n",
      " 3   IncomeRange           object        \n",
      " 4   MaritalStatus         object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(3)\n",
      "memory usage: 126.0+ MB\n"
     ]
    }
   ],
   "source": [
    "household_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountId</th>\n",
       "      <th>HouseholdDateCreated</th>\n",
       "      <th>AgeRange</th>\n",
       "      <th>IncomeRange</th>\n",
       "      <th>MaritalStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000</td>\n",
       "      <td>2013-09-09 17:34:35.930</td>\n",
       "      <td>25-35</td>\n",
       "      <td>$1K-$5K</td>\n",
       "      <td>Divorced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000715</td>\n",
       "      <td>2013-03-09 09:25:53.000</td>\n",
       "      <td>25-35</td>\n",
       "      <td>$25K-$30K</td>\n",
       "      <td>Married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000716</td>\n",
       "      <td>2013-03-11 15:12:11.000</td>\n",
       "      <td>45-55</td>\n",
       "      <td>$10K-$15K</td>\n",
       "      <td>Divorced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000717</td>\n",
       "      <td>2013-03-11 15:09:31.000</td>\n",
       "      <td>45-55</td>\n",
       "      <td>$5K-$10K</td>\n",
       "      <td>Married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000718</td>\n",
       "      <td>2013-03-11 15:21:44.000</td>\n",
       "      <td>25-35</td>\n",
       "      <td>$10K-$15K</td>\n",
       "      <td>Separated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AccountId    HouseholdDateCreated AgeRange IncomeRange MaritalStatus\n",
       "0   10000000 2013-09-09 17:34:35.930    25-35     $1K-$5K      Divorced\n",
       "1   10000715 2013-03-09 09:25:53.000    25-35   $25K-$30K       Married\n",
       "2   10000716 2013-03-11 15:12:11.000    45-55   $10K-$15K      Divorced\n",
       "3   10000717 2013-03-11 15:09:31.000    45-55    $5K-$10K       Married\n",
       "4   10000718 2013-03-11 15:21:44.000    25-35   $10K-$15K     Separated"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "household_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3628189 entries, 0 to 3628188\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Dtype         \n",
      "---  ------                -----         \n",
      " 0   AccountId             int64         \n",
      " 1   PersonId              int64         \n",
      " 2   PersonAccountCreated  datetime64[ns]\n",
      " 3   Active                object        \n",
      " 4   FirstName             object        \n",
      " 5   LastName              object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 166.1+ MB\n"
     ]
    }
   ],
   "source": [
    "person_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountId</th>\n",
       "      <th>PersonId</th>\n",
       "      <th>PersonAccountCreated</th>\n",
       "      <th>Active</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000716</td>\n",
       "      <td>10000716</td>\n",
       "      <td>2013-09-03 15:21:23.943</td>\n",
       "      <td>True</td>\n",
       "      <td>Felecia</td>\n",
       "      <td>Hane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000717</td>\n",
       "      <td>10000717</td>\n",
       "      <td>2013-10-02 12:39:58.913</td>\n",
       "      <td>True</td>\n",
       "      <td>Lena</td>\n",
       "      <td>Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000718</td>\n",
       "      <td>10000718</td>\n",
       "      <td>2013-09-03 15:21:24.117</td>\n",
       "      <td>True</td>\n",
       "      <td>Lular</td>\n",
       "      <td>Stehr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000719</td>\n",
       "      <td>10000719</td>\n",
       "      <td>2013-09-03 15:21:24.207</td>\n",
       "      <td>True</td>\n",
       "      <td>Lona</td>\n",
       "      <td>Goyette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000719</td>\n",
       "      <td>13604747</td>\n",
       "      <td>2019-09-08 16:00:50.320</td>\n",
       "      <td>True</td>\n",
       "      <td>Joey</td>\n",
       "      <td>Morissette</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AccountId  PersonId    PersonAccountCreated Active FirstName    LastName\n",
       "0   10000716  10000716 2013-09-03 15:21:23.943   True   Felecia        Hane\n",
       "1   10000717  10000717 2013-10-02 12:39:58.913   True      Lena      Miller\n",
       "2   10000718  10000718 2013-09-03 15:21:24.117   True     Lular       Stehr\n",
       "3   10000719  10000719 2013-09-03 15:21:24.207   True      Lona     Goyette\n",
       "4   10000719  13604747 2019-09-08 16:00:50.320   True      Joey  Morissette"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2351683 entries, 0 to 2351682\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   AccountId    int64 \n",
      " 1   PersonId     int64 \n",
      " 2   PhoneType    object\n",
      " 3   PhoneId      int64 \n",
      " 4   PhoneNumber  object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 89.7+ MB\n"
     ]
    }
   ],
   "source": [
    "phones_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountId</th>\n",
       "      <th>PersonId</th>\n",
       "      <th>PhoneType</th>\n",
       "      <th>PhoneId</th>\n",
       "      <th>PhoneNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000716</td>\n",
       "      <td>10000716</td>\n",
       "      <td>Home</td>\n",
       "      <td>10001157</td>\n",
       "      <td>+40(5)2649020619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000717</td>\n",
       "      <td>10000717</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>10001158</td>\n",
       "      <td>768-088-2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000717</td>\n",
       "      <td>10000717</td>\n",
       "      <td>Home</td>\n",
       "      <td>10001158</td>\n",
       "      <td>114.595.2874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000718</td>\n",
       "      <td>10000718</td>\n",
       "      <td>Home</td>\n",
       "      <td>10001159</td>\n",
       "      <td>07945401239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000718</td>\n",
       "      <td>10000718</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>10001160</td>\n",
       "      <td>1-296-693-9103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AccountId  PersonId PhoneType   PhoneId       PhoneNumber\n",
       "0   10000716  10000716      Home  10001157  +40(5)2649020619\n",
       "1   10000717  10000717    Mobile  10001158      768-088-2458\n",
       "2   10000717  10000717      Home  10001158      114.595.2874\n",
       "3   10000718  10000718      Home  10001159       07945401239\n",
       "4   10000718  10000718    Mobile  10001160    1-296-693-9103"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phones_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### checking for nan and null values in dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AccountId               0\n",
       "HouseholdDateCreated    8\n",
       "AgeRange                0\n",
       "IncomeRange             0\n",
       "MaritalStatus           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "household_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AccountId               0\n",
       "PersonId                0\n",
       "PersonAccountCreated    0\n",
       "Active                  0\n",
       "FirstName               0\n",
       "LastName                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AccountId      0\n",
       "PersonId       0\n",
       "PhoneType      0\n",
       "PhoneId        0\n",
       "PhoneNumber    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phones_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we don't have nan or null in dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data into Appropriate Format for Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way in which we can ingest data in elasticsearch is a json formate, so first we need to create a json payload from pandas dataframes. we have to create a json payload  by understanding the relationships of features of dataframe so, according to data overview a household could have multiple persons and persons could have multiple phones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create nested documented json payload like this as formated in below example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Household : {'Age_Range': '35-45',\n",
    "             'HouseHoldId': 10000723,\n",
    "             'Income_Range': '$20K-$25K',\n",
    "             'Marital_Status': 'Widowed',\n",
    "             'Person_Details': [{'Active': True,\n",
    "                                 'FirstName': 'Geraldine',\n",
    "                                 'LastName': 'Muller',\n",
    "                                 'PersonId': 10000723,\n",
    "                                 'Phone_Details': [{'PhoneId': 10001169,\n",
    "                                                    'PhoneNumber': '1-981-940-6060',\n",
    "                                                    'PhoneType': 'Mobile'},\n",
    "                                                   {'PhoneId': 10001168,\n",
    "                                                    'PhoneNumber': '+26(1)5732992945',\n",
    "                                                    'PhoneType': 'Mobile'},\n",
    "                                                   {'PhoneId': 10001168,\n",
    "                                                    'PhoneNumber': '09456595885',\n",
    "                                                    'PhoneType': 'Home'}]}],\n",
    "             '_id': 10000723,\n",
    "             '_index': 'household_data_test',\n",
    "             '_type': 'HouseholdInfoDoc'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Need to follow these rules while creating a payload for elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Document should have a unique id so we are assigning it household unique id like this\n",
    "Payload[\"_id\"] : Household Unique Id\n",
    "2. All document should have same doc_type, we can assigne any name, so we are hardcoded it like this \n",
    "Payload[\"_type\"] : \"HouseholdInfoDoc\".\n",
    "2. You have to put the name of index in document which you will have already created in elasticsearch, so we are hardcoded it by the name of index in elasticsearch like this \n",
    "Payload[\"_index\"] : \"household_data_test\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Elasticsearch open kibana go to Dev Tools Console and write a simply command \"PUT Indexname\" for creating new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Annotation 2020-06-17 152824.png\" width=\"1000\" height=\"50\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"Annotation 2020-06-17 152824.png\", width=1000, height=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for whether index has been created successfully or not, open kibana go to Management and select Index Management option, write you index name and search it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Annotation 2020-06-17 154334.png\" width=\"1000\" height=\"50\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"Annotation 2020-06-17 154334.png\", width=1000, height=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see we have successfully created index in elasticsearch and right now Docs_count means documents count is 0 because we don't have ingest any document in it yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here we are going to create appropriate format for elasticsearch from pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "CPU times: user 20min 27s, sys: 2.83 s, total: 20min 30s\n",
      "Wall time: 20min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "BulkDocsContainer=[]\n",
    "i=0\n",
    "for account_values in household_df.itertuples():\n",
    "    i = i + 1\n",
    "    Person_Container=[]\n",
    "    Phone_Container=[]\n",
    "    \n",
    "    Household_Paylod={}\n",
    "    Household_Paylod['_id'] = account_values.AccountId # Document id should be unique key of your data\n",
    "    Household_Paylod[\"_type\"] = \"HouseholdInfoDoc\" # Document type could be any name you want select\n",
    "    Household_Paylod[\"_index\"] = \"household_data_test\"   # Index name same as we have created by name in elasticsearch\n",
    "    \n",
    "    Household_Paylod[\"HouseHoldId\"] = account_values.AccountId\n",
    "    Household_Paylod[\"Age_Range\"] = account_values.AgeRange\n",
    "    Household_Paylod[\"Income_Range\"] = account_values.IncomeRange\n",
    "    Household_Paylod[\"Marital_Status\"] = account_values.MaritalStatus\n",
    "    \n",
    "    per_df = person_df.loc[person_df.AccountId == account_values.AccountId]\n",
    "    \n",
    "    for person_values in per_df.itertuples():\n",
    "        \n",
    "        Person_Paylod={}\n",
    "        Person_Paylod[\"PersonId\"] = person_values.PersonId\n",
    "        Person_Paylod[\"LastName\"] = person_values.LastName\n",
    "        Person_Paylod[\"FirstName\"] = person_values.FirstName\n",
    "        Person_Paylod[\"Active\"] = person_values.Active\n",
    "        \n",
    "        pho_df = phones_df.loc[phones_df.PersonId == person_values.PersonId]\n",
    "    \n",
    "        for phone_values in pho_df.itertuples():\n",
    "            Phone_Paylod={}\n",
    "            Phone_Paylod[\"PhoneId\"] = phone_values.PhoneId\n",
    "            Phone_Paylod[\"PhoneNumber\"] = phone_values.PhoneNumber\n",
    "            Phone_Paylod[\"PhoneType\"] = phone_values.PhoneType\n",
    "            Phone_Container.append(Phone_Paylod)\n",
    "            \n",
    "        Person_Paylod[\"Phone_Details\"] = Phone_Container\n",
    "        \n",
    "        Person_Container.append(Person_Paylod)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Household_Paylod[\"Person_Details\"] = Person_Container\n",
    "    \n",
    "\n",
    "    BulkDocsContainer.append(Household_Paylod)\n",
    "\n",
    "    if i % 100000 == 0:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here as you can see we have break the script at 100000 One_Hundered_Thousent iterations just because it is large scale data and will take time to building a documents bulk on 2 Million households so, now we are just sending One_Hundered_Thousent documents in elasticsearch for test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Ingestion for Bulk Container into Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample of the Document in Bulk Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Age_Range': '35-45',\n",
      " 'HouseHoldId': 10000723,\n",
      " 'Income_Range': '$20K-$25K',\n",
      " 'Marital_Status': 'Widowed',\n",
      " 'Person_Details': [{'Active': True,\n",
      "                     'FirstName': 'Geraldine',\n",
      "                     'LastName': 'Muller',\n",
      "                     'PersonId': 10000723,\n",
      "                     'Phone_Details': [{'PhoneId': 10001169,\n",
      "                                        'PhoneNumber': '1-981-940-6060',\n",
      "                                        'PhoneType': 'Mobile'},\n",
      "                                       {'PhoneId': 10001168,\n",
      "                                        'PhoneNumber': '+26(1)5732992945',\n",
      "                                        'PhoneType': 'Mobile'},\n",
      "                                       {'PhoneId': 10001168,\n",
      "                                        'PhoneNumber': '09456595885',\n",
      "                                        'PhoneType': 'Home'}]}],\n",
      " '_id': 10000723,\n",
      " '_index': 'household_data_test',\n",
      " '_type': 'HouseholdInfoDoc'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(BulkDocsContainer[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Bulk = 100000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of Bulk = \" +str(len(BulkDocsContainer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here we are going to hit the bulk to Ingesting data in elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try:\n",
    "    response = helpers.bulk(es, BulkDocsContainer)\n",
    "    print (\"\\nActions RESPONSE:\", response)\n",
    "except Exception as e:\n",
    "    print(\"\\nERROR:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the Docs Count is 100000 after ingesting Data into elasticsearch in bulk structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Annotation 2020-06-17 165734.png\" width=\"10000\" height=\"50\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"Annotation 2020-06-17 165734.png\", width=10000, height=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Annotation 2020-06-17 165640.png\" width=\"10000\" height=\"50\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"Annotation 2020-06-17 165640.png\", width=10000, height=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Annotation 2020-06-17 165616.png\" width=\"10000\" height=\"50\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"Annotation 2020-06-17 165616.png\", width=10000, height=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using these strategies we can ingest our data in elasticsearch and build beautiful dashboards kibana and apply quick search in apps beckend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Annotation 2020-06-17 1657399.jpg\" width=\"10000\" height=\"50\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"Annotation 2020-06-17 1657399.jpg\", width=10000, height=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
